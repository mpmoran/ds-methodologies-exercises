{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - Model Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acquire import get_titanic_data, get_iris_data\n",
    "from prepare import prep_titanic, split_titanic, min_max_scale_titanic, prep_iris\n",
    "\n",
    "from collections import namedtuple\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import adalib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(object):\n",
    "    def __init__(self):\n",
    "        self.df = None\n",
    "        self.train = None\n",
    "        self.test = None\n",
    "        self.xcols = None\n",
    "        self.model = None\n",
    "        self.pred_train = None\n",
    "        self.pred_test = None\n",
    "        self.score = None\n",
    "        self.confmatrix = None\n",
    "        self.classrep = None\n",
    "        self.precision = None\n",
    "        self.recall = None\n",
    "        self.f1 = None\n",
    "        self.support = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_titanic = DataSet()\n",
    "lr_titanic.df = get_titanic_data()\n",
    "lr_titanic.df = prep_titanic(lr_titanic.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lr_titanic.train, lr_titanic.test = split_titanic(lr_titanic.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_titanic.train, lr_titanic.test = min_max_scale_titanic(lr_titanic.train, lr_titanic.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Fit the logistic regression classifier to your training sample and transform, i.e. make predictions on the training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_titanic.xcols = [\"pclass\", \"age\", \"sibsp\", \"parch\", \"fare\", \"alone\", \"embarked_encode\", \"sex_encode\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN EVALUATION\n",
      "Accuracy: 0.7915831663326653\n",
      "\n",
      "Confusion matrix:\n",
      "          Pred -  Pred +\n",
      "Actual -     254      42\n",
      "Actual +      62     141\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       296\n",
      "           1       0.77      0.69      0.73       203\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       499\n",
      "   macro avg       0.79      0.78      0.78       499\n",
      "weighted avg       0.79      0.79      0.79       499\n",
      "\n",
      "\n",
      "Rates:\n",
      "True positive rate: 0.6945812807881774\n",
      "False positive rate: 0.22950819672131148\n",
      "True negative rate: 0.8581081081081081\n",
      "False negative rate: 0.1962025316455696\n",
      "\n",
      "TEST EVALUATION\n",
      "Accuracy: 0.7674418604651163\n",
      "\n",
      "Confusion matrix:\n",
      "          Pred -  Pred +\n",
      "Actual -     105      23\n",
      "Actual +      27      60\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81       128\n",
      "           1       0.72      0.69      0.71        87\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       215\n",
      "   macro avg       0.76      0.75      0.76       215\n",
      "weighted avg       0.77      0.77      0.77       215\n",
      "\n",
      "\n",
      "Rates:\n",
      "True positive rate: 0.6896551724137931\n",
      "False positive rate: 0.27710843373493976\n",
      "True negative rate: 0.8203125\n",
      "False negative rate: 0.20454545454545456\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "adalib.logreg_model(lr_titanic.train[lr_titanic.xcols], lr_titanic.train.survived, lr_titanic.test[lr_titanic.xcols], lr_titanic.test.survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Look in the scikit-learn documentation to research the solver parameter. What is your best option(s) for the particular problem you are trying to solve and the data to be used?\n",
    "\n",
    "liblinear because this is a small dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Run through steps 2-4 using another solver (from question 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN EVALUATION\n",
      "Accuracy: 0.8016032064128257\n",
      "\n",
      "Confusion matrix:\n",
      "          Pred -  Pred +\n",
      "Actual -     258      38\n",
      "Actual +      61     142\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84       296\n",
      "           1       0.79      0.70      0.74       203\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       499\n",
      "   macro avg       0.80      0.79      0.79       499\n",
      "weighted avg       0.80      0.80      0.80       499\n",
      "\n",
      "\n",
      "Rates:\n",
      "True positive rate: 0.6995073891625616\n",
      "False positive rate: 0.2111111111111111\n",
      "True negative rate: 0.8716216216216216\n",
      "False negative rate: 0.19122257053291536\n",
      "\n",
      "TEST EVALUATION\n",
      "Accuracy: 0.7767441860465116\n",
      "\n",
      "Confusion matrix:\n",
      "          Pred -  Pred +\n",
      "Actual -     101      27\n",
      "Actual +      21      66\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81       128\n",
      "           1       0.71      0.76      0.73        87\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       215\n",
      "   macro avg       0.77      0.77      0.77       215\n",
      "weighted avg       0.78      0.78      0.78       215\n",
      "\n",
      "\n",
      "Rates:\n",
      "True positive rate: 0.7586206896551724\n",
      "False positive rate: 0.2903225806451613\n",
      "True negative rate: 0.7890625\n",
      "False negative rate: 0.1721311475409836\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newton_preds_train, newton_preds_test, newton_model = adalib.logreg_fit_and_predict(lr_titanic.train[lr_titanic.xcols], lr_titanic.train.survived, lr_titanic.test[lr_titanic.xcols], lr_titanic.test.survived, solver=\"newton-cg\")\n",
    "print(\"TRAIN EVALUATION\")\n",
    "adalib.logreg_evaluate_model(lr_titanic.train.survived, newton_preds_train)\n",
    "\n",
    "print(\"TEST EVALUATION\")\n",
    "adalib.logreg_evaluate_model(lr_titanic.test.survived, newton_preds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Which performs better on your in-sample data?\n",
    "\n",
    "newton-cg, but not by much (about ~0.1 more accurate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Save the best model in logit_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_fit = newton_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = DataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.df = get_iris_data()\n",
    "iris.df = prep_iris(iris.df)\n",
    "iris.train, iris.test = train_test_split(iris.df, test_size=0.3, random_state=123, stratify=iris.df[[\"species\"]])\n",
    "iris.xcols = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN EVALUATION\n",
      "Accuracy: 1.0\n",
      "\n",
      "Confusion matrix:\n",
      "                   Pred setosa  Pred versicolor  Pred virginica\n",
      "Actual setosa               35                0               0\n",
      "Actual versicolor            0               35               0\n",
      "Actual virginica             0                0              35\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        35\n",
      "  versicolor       1.00      1.00      1.00        35\n",
      "   virginica       1.00      1.00      1.00        35\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       105\n",
      "   macro avg       1.00      1.00      1.00       105\n",
      "weighted avg       1.00      1.00      1.00       105\n",
      "\n",
      "\n",
      "True setosa rate:  1.000\n",
      "False setosa rate:  0.000\n",
      "\n",
      "True versicolor rate:  1.000\n",
      "False versicolor rate:  0.000\n",
      "\n",
      "True virginica rate:  1.000\n",
      "False virginica rate:  0.000\n",
      "\n",
      "TEST EVALUATION\n",
      "Accuracy: 0.8888888888888888\n",
      "\n",
      "Confusion matrix:\n",
      "                   Pred setosa  Pred versicolor  Pred virginica\n",
      "Actual setosa               15                0               0\n",
      "Actual versicolor            0               12               3\n",
      "Actual virginica             0                2              13\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        15\n",
      "  versicolor       0.86      0.80      0.83        15\n",
      "   virginica       0.81      0.87      0.84        15\n",
      "\n",
      "   micro avg       0.89      0.89      0.89        45\n",
      "   macro avg       0.89      0.89      0.89        45\n",
      "weighted avg       0.89      0.89      0.89        45\n",
      "\n",
      "\n",
      "True setosa rate:  1.000\n",
      "False setosa rate:  0.000\n",
      "\n",
      "True versicolor rate:  0.800\n",
      "False versicolor rate:  0.143\n",
      "\n",
      "True virginica rate:  0.867\n",
      "False virginica rate:  0.188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris.pred_train, iris.pred_test, iris.classes, iris.model = adalib.dectree_fit_and_predict(\n",
    "    iris.train[iris.xcols], iris.train.species, iris.test[iris.xcols], iris.test.species\n",
    ")\n",
    "\n",
    "print(\"TRAIN EVALUATION\")\n",
    "adalib.dectree_evaluate_model(iris.train.species, iris.pred_train, iris.classes)\n",
    "\n",
    "print(\"TEST EVALUATION\")\n",
    "adalib.dectree_evaluate_model(iris.test.species, iris.pred_test, iris.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run through steps 2-4 using entropy as your measure of impurity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_entropy = DataSet()\n",
    "iris_entropy.df = iris.df\n",
    "iris_entropy.train = iris.train\n",
    "iris_entropy.test = iris.test\n",
    "iris_entropy.xcols = iris.xcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN EVALUATION\n",
      "Accuracy: 1.0\n",
      "\n",
      "Confusion matrix:\n",
      "                   Pred setosa  Pred versicolor  Pred virginica\n",
      "Actual setosa               35                0               0\n",
      "Actual versicolor            0               35               0\n",
      "Actual virginica             0                0              35\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        35\n",
      "  versicolor       1.00      1.00      1.00        35\n",
      "   virginica       1.00      1.00      1.00        35\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       105\n",
      "   macro avg       1.00      1.00      1.00       105\n",
      "weighted avg       1.00      1.00      1.00       105\n",
      "\n",
      "\n",
      "True setosa rate:  1.000\n",
      "False setosa rate:  0.000\n",
      "\n",
      "True versicolor rate:  1.000\n",
      "False versicolor rate:  0.000\n",
      "\n",
      "True virginica rate:  1.000\n",
      "False virginica rate:  0.000\n",
      "\n",
      "TEST EVALUATION\n",
      "Accuracy: 0.9111111111111111\n",
      "\n",
      "Confusion matrix:\n",
      "                   Pred setosa  Pred versicolor  Pred virginica\n",
      "Actual setosa               15                0               0\n",
      "Actual versicolor            0               12               3\n",
      "Actual virginica             0                1              14\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        15\n",
      "  versicolor       0.92      0.80      0.86        15\n",
      "   virginica       0.82      0.93      0.87        15\n",
      "\n",
      "   micro avg       0.91      0.91      0.91        45\n",
      "   macro avg       0.92      0.91      0.91        45\n",
      "weighted avg       0.92      0.91      0.91        45\n",
      "\n",
      "\n",
      "True setosa rate:  1.000\n",
      "False setosa rate:  0.000\n",
      "\n",
      "True versicolor rate:  0.800\n",
      "False versicolor rate:  0.077\n",
      "\n",
      "True virginica rate:  0.933\n",
      "False virginica rate:  0.176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris_entropy.pred_train, iris_entropy.pred_test, iris_entropy.classes, iris_entropy.model = adalib.dectree_fit_and_predict(\n",
    "    iris_entropy.train[iris_entropy.xcols], iris_entropy.train.species, iris_entropy.test[iris_entropy.xcols], iris_entropy.test.species, criterion=\"entropy\"\n",
    ")\n",
    "\n",
    "print(\"TRAIN EVALUATION\")\n",
    "adalib.dectree_evaluate_model(iris_entropy.train.species, iris_entropy.pred_train, iris_entropy.classes)\n",
    "\n",
    "print(\"TEST EVALUATION\")\n",
    "adalib.dectree_evaluate_model(iris_entropy.test.species, iris_entropy.pred_test, iris_entropy.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Which performs better on your in-sample data?\n",
    "\n",
    "They both perform equally well on the training data. 100% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to run this on the titanic data and then if i have time, create a function to do the decision tree and analysis, then run the test data through the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Save the best model in tree_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_fit = iris_entropy.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_titanic = DataSet()\n",
    "dt_titanic.df = get_titanic_data()\n",
    "dt_titanic.df = prep_titanic(dt_titanic.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "dt_titanic.train, dt_titanic.test = split_titanic(dt_titanic.df)\n",
    "dt_titanic.train, dt_titanic.test = min_max_scale_titanic(dt_titanic.train, dt_titanic.test)\n",
    "dt_titanic.xcols = [\"pclass\", \"age\", \"sibsp\", \"parch\", \"fare\", \"alone\", \"embarked_encode\", \"sex_encode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN EVALUATION\n",
      "Accuracy: 0.843687374749499\n",
      "\n",
      "Confusion matrix:\n",
      "          Pred 0  Pred 1\n",
      "Actual 0     261      35\n",
      "Actual 1      43     160\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87       296\n",
      "           1       0.82      0.79      0.80       203\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       499\n",
      "   macro avg       0.84      0.83      0.84       499\n",
      "weighted avg       0.84      0.84      0.84       499\n",
      "\n",
      "\n",
      "True 0 rate:  0.882\n",
      "False 0 rate:  0.141\n",
      "\n",
      "True 1 rate:  0.788\n",
      "False 1 rate:  0.179\n",
      "\n",
      "TEST EVALUATION\n",
      "Accuracy: 0.813953488372093\n",
      "\n",
      "Confusion matrix:\n",
      "          Pred 0  Pred 1\n",
      "Actual 0     105      23\n",
      "Actual 1      17      70\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84       128\n",
      "           1       0.75      0.80      0.78        87\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       215\n",
      "   macro avg       0.81      0.81      0.81       215\n",
      "weighted avg       0.82      0.81      0.81       215\n",
      "\n",
      "\n",
      "True 0 rate:  0.820\n",
      "False 0 rate:  0.139\n",
      "\n",
      "True 1 rate:  0.805\n",
      "False 1 rate:  0.247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_titanic.pred_train, dt_titanic.pred_test, dt_titanic.classes, dt_titanic.model = adalib.dectree_fit_and_predict(\n",
    "    dt_titanic.train[dt_titanic.xcols], dt_titanic.train.survived, dt_titanic.test[dt_titanic.xcols], dt_titanic.test.survived, max_depth=4\n",
    ")\n",
    "\n",
    "print(\"TRAIN EVALUATION\")\n",
    "adalib.dectree_evaluate_model(dt_titanic.train.survived, dt_titanic.pred_train, dt_titanic.classes)\n",
    "\n",
    "print(\"TEST EVALUATION\")\n",
    "adalib.dectree_evaluate_model(dt_titanic.test.survived, dt_titanic.pred_test, dt_titanic.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_titanic_entropy = DataSet()\n",
    "dt_titanic_entropy.df = get_titanic_data()\n",
    "dt_titanic_entropy.df = prep_titanic(dt_titanic_entropy.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "dt_titanic_entropy.train, dt_titanic_entropy.test = split_titanic(dt_titanic_entropy.df)\n",
    "dt_titanic_entropy.train, dt_titanic_entropy.test = min_max_scale_titanic(dt_titanic_entropy.train, dt_titanic_entropy.test)\n",
    "dt_titanic_entropy.xcols = [\"pclass\", \"age\", \"sibsp\", \"parch\", \"fare\", \"alone\", \"embarked_encode\", \"sex_encode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN EVALUATION\n",
      "Accuracy: 0.8557114228456913\n",
      "\n",
      "Confusion matrix:\n",
      "          Pred 0  Pred 1\n",
      "Actual 0     289       7\n",
      "Actual 1      65     138\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89       296\n",
      "           1       0.95      0.68      0.79       203\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       499\n",
      "   macro avg       0.88      0.83      0.84       499\n",
      "weighted avg       0.87      0.86      0.85       499\n",
      "\n",
      "\n",
      "True 0 rate:  0.976\n",
      "False 0 rate:  0.184\n",
      "\n",
      "True 1 rate:  0.680\n",
      "False 1 rate:  0.048\n",
      "\n",
      "TEST EVALUATION\n",
      "Accuracy: 0.8\n",
      "\n",
      "Confusion matrix:\n",
      "          Pred 0  Pred 1\n",
      "Actual 0     123       5\n",
      "Actual 1      38      49\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.96      0.85       128\n",
      "           1       0.91      0.56      0.70        87\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       215\n",
      "   macro avg       0.84      0.76      0.77       215\n",
      "weighted avg       0.82      0.80      0.79       215\n",
      "\n",
      "\n",
      "True 0 rate:  0.961\n",
      "False 0 rate:  0.236\n",
      "\n",
      "True 1 rate:  0.563\n",
      "False 1 rate:  0.093\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_titanic_entropy.pred_train, dt_titanic_entropy.pred_test, dt_titanic_entropy.classes, dt_titanic_entropy.model = adalib.dectree_fit_and_predict(\n",
    "    dt_titanic_entropy.train[dt_titanic_entropy.xcols], dt_titanic_entropy.train.survived, dt_titanic_entropy.test[dt_titanic_entropy.xcols], dt_titanic_entropy.test.survived, criterion=\"entropy\",\n",
    "    max_depth=5\n",
    ")\n",
    "\n",
    "print(\"TRAIN EVALUATION\")\n",
    "adalib.dectree_evaluate_model(dt_titanic_entropy.train.survived, dt_titanic_entropy.pred_train, dt_titanic_entropy.classes)\n",
    "\n",
    "print(\"TEST EVALUATION\")\n",
    "adalib.dectree_evaluate_model(dt_titanic_entropy.test.survived, dt_titanic_entropy.pred_test, dt_titanic_entropy.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fit the K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_titanic = DataSet()\n",
    "knn_titanic.df = get_titanic_data()\n",
    "knn_titanic.df = prep_titanic(knn_titanic.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "knn_titanic.train, knn_titanic.test = split_titanic(knn_titanic.df)\n",
    "knn_titanic.train, knn_titanic.test = min_max_scale_titanic(knn_titanic.train, knn_titanic.test)\n",
    "knn_titanic.xcols = [\"pclass\", \"age\", \"sibsp\", \"parch\", \"fare\", \"alone\", \"embarked_encode\", \"sex_encode\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better than logistic regression, but not as good as random forest w/ gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN EVALUATION\n",
      "Accuracy: 0.8416833667334669\n",
      "\n",
      "Confusion matrix:\n",
      "                    Pred Not Survive  Pred Survive\n",
      "Actual Not Survive               284            12\n",
      "Actual Survive                    67           136\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88       296\n",
      "           1       0.92      0.67      0.77       203\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       499\n",
      "   macro avg       0.86      0.81      0.83       499\n",
      "weighted avg       0.85      0.84      0.84       499\n",
      "\n",
      "\n",
      "True Not Survive rate:  0.959\n",
      "False Not Survive rate:  0.191\n",
      "\n",
      "True Survive rate:  0.670\n",
      "False Survive rate:  0.081\n",
      "\n",
      "TEST EVALUATION\n",
      "Accuracy: 0.7906976744186046\n",
      "\n",
      "Confusion matrix:\n",
      "                    Pred Not Survive  Pred Survive\n",
      "Actual Not Survive               114            14\n",
      "Actual Survive                    31            56\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84       128\n",
      "           1       0.80      0.64      0.71        87\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       215\n",
      "   macro avg       0.79      0.77      0.77       215\n",
      "weighted avg       0.79      0.79      0.79       215\n",
      "\n",
      "\n",
      "True Not Survive rate:  0.891\n",
      "False Not Survive rate:  0.214\n",
      "\n",
      "True Survive rate:  0.644\n",
      "False Survive rate:  0.200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_titanic.pred_train, knn_titanic.pred_test, knn_titanic.classes, knn_titanic.model = adalib.knn_fit_and_predict(\n",
    "    knn_titanic.train[knn_titanic.xcols], knn_titanic.train.survived, knn_titanic.test[knn_titanic.xcols], knn_titanic.test.survived,\n",
    "    n_neighbors=4, weights=\"uniform\"\n",
    ")\n",
    "\n",
    "knn_4 = knn_titanic.model\n",
    "\n",
    "print(\"TRAIN EVALUATION\")\n",
    "adalib.knn_evaluate_model(knn_titanic.train.survived, knn_titanic.pred_train, (\"Not Survive\", \"Survive\"))\n",
    "\n",
    "print(\"TEST EVALUATION\")\n",
    "adalib.knn_evaluate_model(knn_titanic.test.survived, knn_titanic.pred_test, (\"Not Survive\", \"Survive\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run through steps 2-4 setting k to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN EVALUATION\n",
      "Accuracy: 0.8216432865731463\n",
      "\n",
      "Confusion matrix:\n",
      "                    Pred Not Survive  Pred Survive\n",
      "Actual Not Survive               277            19\n",
      "Actual Survive                    70           133\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.86       296\n",
      "           1       0.88      0.66      0.75       203\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       499\n",
      "   macro avg       0.84      0.80      0.81       499\n",
      "weighted avg       0.83      0.82      0.82       499\n",
      "\n",
      "\n",
      "True Not Survive rate:  0.936\n",
      "False Not Survive rate:  0.202\n",
      "\n",
      "True Survive rate:  0.655\n",
      "False Survive rate:  0.125\n",
      "\n",
      "TEST EVALUATION\n",
      "Accuracy: 0.7906976744186046\n",
      "\n",
      "Confusion matrix:\n",
      "                    Pred Not Survive  Pred Survive\n",
      "Actual Not Survive               114            14\n",
      "Actual Survive                    31            56\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84       128\n",
      "           1       0.80      0.64      0.71        87\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       215\n",
      "   macro avg       0.79      0.77      0.77       215\n",
      "weighted avg       0.79      0.79      0.79       215\n",
      "\n",
      "\n",
      "True Not Survive rate:  0.891\n",
      "False Not Survive rate:  0.214\n",
      "\n",
      "True Survive rate:  0.644\n",
      "False Survive rate:  0.200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_titanic.pred_train, knn_titanic.pred_test, knn_titanic.classes, knn_titanic.model = adalib.knn_fit_and_predict(\n",
    "    knn_titanic.train[knn_titanic.xcols], knn_titanic.train.survived, knn_titanic.test[knn_titanic.xcols], knn_titanic.test.survived,\n",
    "    n_neighbors=10, weights=\"uniform\"\n",
    ")\n",
    "\n",
    "knn_10 = knn_titanic.model\n",
    "\n",
    "print(\"TRAIN EVALUATION\")\n",
    "adalib.knn_evaluate_model(knn_titanic.train.survived, knn_titanic.pred_train, (\"Not Survive\", \"Survive\"))\n",
    "\n",
    "print(\"TEST EVALUATION\")\n",
    "adalib.knn_evaluate_model(knn_titanic.test.survived, knn_titanic.pred_test, (\"Not Survive\", \"Survive\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not as good as random forest w/ gini and about the same as k=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Run through setps 2-4 setting k to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN EVALUATION\n",
      "Accuracy: 0.8096192384769539\n",
      "\n",
      "Confusion matrix:\n",
      "                    Pred Not Survive  Pred Survive\n",
      "Actual Not Survive               271            25\n",
      "Actual Survive                    70           133\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85       296\n",
      "           1       0.84      0.66      0.74       203\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       499\n",
      "   macro avg       0.82      0.79      0.79       499\n",
      "weighted avg       0.81      0.81      0.80       499\n",
      "\n",
      "\n",
      "True Not Survive rate:  0.916\n",
      "False Not Survive rate:  0.205\n",
      "\n",
      "True Survive rate:  0.655\n",
      "False Survive rate:  0.158\n",
      "\n",
      "TEST EVALUATION\n",
      "Accuracy: 0.7488372093023256\n",
      "\n",
      "Confusion matrix:\n",
      "                    Pred Not Survive  Pred Survive\n",
      "Actual Not Survive               108            20\n",
      "Actual Survive                    34            53\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.84      0.80       128\n",
      "           1       0.73      0.61      0.66        87\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       215\n",
      "   macro avg       0.74      0.73      0.73       215\n",
      "weighted avg       0.75      0.75      0.74       215\n",
      "\n",
      "\n",
      "True Not Survive rate:  0.844\n",
      "False Not Survive rate:  0.239\n",
      "\n",
      "True Survive rate:  0.609\n",
      "False Survive rate:  0.274\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_titanic.pred_train, knn_titanic.pred_test, knn_titanic.classes, knn_titanic.model = adalib.knn_fit_and_predict(\n",
    "    knn_titanic.train[knn_titanic.xcols], knn_titanic.train.survived, knn_titanic.test[knn_titanic.xcols], knn_titanic.test.survived,\n",
    "    n_neighbors=20, weights=\"uniform\"\n",
    ")\n",
    "\n",
    "knn_20 = knn_titanic.model\n",
    "\n",
    "print(\"TRAIN EVALUATION\")\n",
    "adalib.knn_evaluate_model(knn_titanic.train.survived, knn_titanic.pred_train, (\"Not Survive\", \"Survive\"))\n",
    "\n",
    "print(\"TEST EVALUATION\")\n",
    "adalib.knn_evaluate_model(knn_titanic.test.survived, knn_titanic.pred_test, (\"Not Survive\", \"Survive\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k = 20 is worse than k = 4 or 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n",
    "Measured on TEST data\n",
    "Accuracy (highest to lowest): 4, 10, 20\n",
    "True rates (highest to lowest): 4 & 10 (tie), 20\n",
    "False rates (lowest to highest): 4 & 10 (tie), 20\n",
    "\n",
    "I'd go with 4 because it is less complex given that it calculates only the 4 nearest neighbors, not 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Save the best model in knn_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_fit = knn_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_iris = DataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_iris.df = get_iris_data()\n",
    "knn_iris.df = prep_iris(knn_iris.df)\n",
    "knn_iris.train, knn_iris.test = train_test_split(knn_iris.df, test_size=0.3, random_state=123, stratify=knn_iris.df[[\"species\"]])\n",
    "knn_iris.xcols = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fit the K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN EVALUATION\n",
      "Accuracy: 0.9809523809523809\n",
      "\n",
      "Confusion matrix:\n",
      "                   Pred setosa  Pred versicolor  Pred virginica\n",
      "Actual setosa               35                0               0\n",
      "Actual versicolor            0               34               1\n",
      "Actual virginica             0                1              34\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        35\n",
      "  versicolor       0.97      0.97      0.97        35\n",
      "   virginica       0.97      0.97      0.97        35\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       105\n",
      "   macro avg       0.98      0.98      0.98       105\n",
      "weighted avg       0.98      0.98      0.98       105\n",
      "\n",
      "\n",
      "True setosa rate:  1.000\n",
      "False setosa rate:  0.000\n",
      "\n",
      "True versicolor rate:  0.971\n",
      "False versicolor rate:  0.029\n",
      "\n",
      "True virginica rate:  0.971\n",
      "False virginica rate:  0.029\n",
      "\n",
      "TEST EVALUATION\n",
      "Accuracy: 0.9555555555555556\n",
      "\n",
      "Confusion matrix:\n",
      "                   Pred setosa  Pred versicolor  Pred virginica\n",
      "Actual setosa               15                0               0\n",
      "Actual versicolor            0               13               2\n",
      "Actual virginica             0                0              15\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        15\n",
      "  versicolor       1.00      0.87      0.93        15\n",
      "   virginica       0.88      1.00      0.94        15\n",
      "\n",
      "   micro avg       0.96      0.96      0.96        45\n",
      "   macro avg       0.96      0.96      0.96        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "\n",
      "True setosa rate:  1.000\n",
      "False setosa rate:  0.000\n",
      "\n",
      "True versicolor rate:  0.867\n",
      "False versicolor rate:  0.000\n",
      "\n",
      "True virginica rate:  1.000\n",
      "False virginica rate:  0.118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_iris.pred_train, knn_iris.pred_test, knn_iris.classes, knn_iris.model = adalib.knn_fit_and_predict(\n",
    "    knn_iris.train[knn_iris.xcols], knn_iris.train.species, knn_iris.test[knn_iris.xcols], knn_iris.test.species,\n",
    "    n_neighbors=5, weights=\"uniform\"\n",
    ")\n",
    "\n",
    "knn_5 = knn_iris.model\n",
    "\n",
    "print(\"TRAIN EVALUATION\")\n",
    "adalib.knn_evaluate_model(knn_iris.train.species, knn_iris.pred_train, knn_iris.classes)\n",
    "\n",
    "print(\"TEST EVALUATION\")\n",
    "adalib.knn_evaluate_model(knn_iris.test.species, knn_iris.pred_test, knn_iris.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run through steps 2-4 setting k to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN EVALUATION\n",
      "Accuracy: 0.9809523809523809\n",
      "\n",
      "Confusion matrix:\n",
      "                   Pred setosa  Pred versicolor  Pred virginica\n",
      "Actual setosa               35                0               0\n",
      "Actual versicolor            0               34               1\n",
      "Actual virginica             0                1              34\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        35\n",
      "  versicolor       0.97      0.97      0.97        35\n",
      "   virginica       0.97      0.97      0.97        35\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       105\n",
      "   macro avg       0.98      0.98      0.98       105\n",
      "weighted avg       0.98      0.98      0.98       105\n",
      "\n",
      "\n",
      "True setosa rate:  1.000\n",
      "False setosa rate:  0.000\n",
      "\n",
      "True versicolor rate:  0.971\n",
      "False versicolor rate:  0.029\n",
      "\n",
      "True virginica rate:  0.971\n",
      "False virginica rate:  0.029\n",
      "\n",
      "TEST EVALUATION\n",
      "Accuracy: 0.9777777777777777\n",
      "\n",
      "Confusion matrix:\n",
      "                   Pred setosa  Pred versicolor  Pred virginica\n",
      "Actual setosa               15                0               0\n",
      "Actual versicolor            0               14               1\n",
      "Actual virginica             0                0              15\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        15\n",
      "  versicolor       1.00      0.93      0.97        15\n",
      "   virginica       0.94      1.00      0.97        15\n",
      "\n",
      "   micro avg       0.98      0.98      0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "\n",
      "True setosa rate:  1.000\n",
      "False setosa rate:  0.000\n",
      "\n",
      "True versicolor rate:  0.933\n",
      "False versicolor rate:  0.000\n",
      "\n",
      "True virginica rate:  1.000\n",
      "False virginica rate:  0.062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_iris.pred_train, knn_iris.pred_test, knn_iris.classes, knn_iris.model = adalib.knn_fit_and_predict(\n",
    "    knn_iris.train[knn_iris.xcols], knn_iris.train.species, knn_iris.test[knn_iris.xcols], knn_iris.test.species,\n",
    "    n_neighbors=10, weights=\"uniform\"\n",
    ")\n",
    "\n",
    "knn_10 = knn_iris.model\n",
    "\n",
    "print(\"TRAIN EVALUATION\")\n",
    "adalib.knn_evaluate_model(knn_iris.train.species, knn_iris.pred_train, knn_iris.classes)\n",
    "\n",
    "print(\"TEST EVALUATION\")\n",
    "adalib.knn_evaluate_model(knn_iris.test.species, knn_iris.pred_test, knn_iris.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Run through setps 2-4 setting k to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN EVALUATION\n",
      "Accuracy: 0.9619047619047619\n",
      "\n",
      "Confusion matrix:\n",
      "                   Pred setosa  Pred versicolor  Pred virginica\n",
      "Actual setosa               35                0               0\n",
      "Actual versicolor            0               33               2\n",
      "Actual virginica             0                2              33\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        35\n",
      "  versicolor       0.94      0.94      0.94        35\n",
      "   virginica       0.94      0.94      0.94        35\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       105\n",
      "   macro avg       0.96      0.96      0.96       105\n",
      "weighted avg       0.96      0.96      0.96       105\n",
      "\n",
      "\n",
      "True setosa rate:  1.000\n",
      "False setosa rate:  0.000\n",
      "\n",
      "True versicolor rate:  0.943\n",
      "False versicolor rate:  0.057\n",
      "\n",
      "True virginica rate:  0.943\n",
      "False virginica rate:  0.057\n",
      "\n",
      "TEST EVALUATION\n",
      "Accuracy: 0.9555555555555556\n",
      "\n",
      "Confusion matrix:\n",
      "                   Pred setosa  Pred versicolor  Pred virginica\n",
      "Actual setosa               15                0               0\n",
      "Actual versicolor            0               14               1\n",
      "Actual virginica             0                1              14\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        15\n",
      "  versicolor       0.93      0.93      0.93        15\n",
      "   virginica       0.93      0.93      0.93        15\n",
      "\n",
      "   micro avg       0.96      0.96      0.96        45\n",
      "   macro avg       0.96      0.96      0.96        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "\n",
      "True setosa rate:  1.000\n",
      "False setosa rate:  0.000\n",
      "\n",
      "True versicolor rate:  0.933\n",
      "False versicolor rate:  0.067\n",
      "\n",
      "True virginica rate:  0.933\n",
      "False virginica rate:  0.067\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_iris.pred_train, knn_iris.pred_test, knn_iris.classes, knn_iris.model = adalib.knn_fit_and_predict(\n",
    "    knn_iris.train[knn_iris.xcols], knn_iris.train.species, knn_iris.test[knn_iris.xcols], knn_iris.test.species,\n",
    "    n_neighbors=20, weights=\"uniform\"\n",
    ")\n",
    "\n",
    "knn_20 = knn_iris.model\n",
    "\n",
    "print(\"TRAIN EVALUATION\")\n",
    "adalib.knn_evaluate_model(knn_iris.train.species, knn_iris.pred_train, knn_iris.classes)\n",
    "\n",
    "print(\"TEST EVALUATION\")\n",
    "adalib.knn_evaluate_model(knn_iris.test.species, knn_iris.pred_test, knn_iris.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Save the best model in knn_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run through steps increasing your min_samples_leaf to 5 and decreasing your max_depth to 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Save the best model in forest_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run through steps increasing your min_samples_leaf to 5 and decreasing your max_depth to 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Save the best model in forest_fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
