{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - Model Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acquire import get_titanic_data, get_iris_data\n",
    "from prepare import prep_titanic, split_titanic, min_max_scale_titanic, prep_iris\n",
    "\n",
    "from collections import namedtuple\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import adalib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(object):\n",
    "    def __init__(self):\n",
    "        self.df = None\n",
    "        self.train = None\n",
    "        self.test = None\n",
    "        self.xcols = None\n",
    "        self.model = None\n",
    "        self.pred_train = None\n",
    "        self.pred_test = None\n",
    "        self.score = None\n",
    "        self.confmatrix = None\n",
    "        self.classrep = None\n",
    "        self.precision = None\n",
    "        self.recall = None\n",
    "        self.f1 = None\n",
    "        self.support = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_titanic = DataSet()\n",
    "lr_titanic.df = get_titanic_data()\n",
    "lr_titanic.df = prep_titanic(lr_titanic.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lr_titanic.train, lr_titanic.test = split_titanic(lr_titanic.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_titanic.train, lr_titanic.test = min_max_scale_titanic(lr_titanic.train, lr_titanic.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Fit the logistic regression classifier to your training sample and transform, i.e. make predictions on the training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_titanic.xcols = [\"pclass\", \"age\", \"sibsp\", \"parch\", \"fare\", \"alone\", \"embarked_encode\", \"sex_encode\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN EVALUATION\n",
      "Accuracy: 0.7915831663326653\n",
      "\n",
      "Confusion matrix:\n",
      "          Pred -  Pred +\n",
      "Actual -     254      42\n",
      "Actual +      62     141\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       296\n",
      "           1       0.77      0.69      0.73       203\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       499\n",
      "   macro avg       0.79      0.78      0.78       499\n",
      "weighted avg       0.79      0.79      0.79       499\n",
      "\n",
      "\n",
      "Rates:\n",
      "True positive rate: 0.6945812807881774\n",
      "False positive rate: 0.22950819672131148\n",
      "True negative rate: 0.8581081081081081\n",
      "False negative rate: 0.1962025316455696\n",
      "\n",
      "TEST EVALUATION\n",
      "Accuracy: 0.7674418604651163\n",
      "\n",
      "Confusion matrix:\n",
      "          Pred -  Pred +\n",
      "Actual -     105      23\n",
      "Actual +      27      60\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81       128\n",
      "           1       0.72      0.69      0.71        87\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       215\n",
      "   macro avg       0.76      0.75      0.76       215\n",
      "weighted avg       0.77      0.77      0.77       215\n",
      "\n",
      "\n",
      "Rates:\n",
      "True positive rate: 0.6896551724137931\n",
      "False positive rate: 0.27710843373493976\n",
      "True negative rate: 0.8203125\n",
      "False negative rate: 0.20454545454545456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adalib.logreg_model(lr_titanic.train[lr_titanic.xcols], lr_titanic.train.survived, lr_titanic.test[lr_titanic.xcols], lr_titanic.test.survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Look in the scikit-learn documentation to research the solver parameter. What is your best option(s) for the particular problem you are trying to solve and the data to be used?\n",
    "\n",
    "liblinear because this is a small dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Run through steps 2-4 using another solver (from question 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN EVALUATION\n",
      "Accuracy: 0.8016032064128257\n",
      "\n",
      "Confusion matrix:\n",
      "          Pred -  Pred +\n",
      "Actual -     258      38\n",
      "Actual +      61     142\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84       296\n",
      "           1       0.79      0.70      0.74       203\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       499\n",
      "   macro avg       0.80      0.79      0.79       499\n",
      "weighted avg       0.80      0.80      0.80       499\n",
      "\n",
      "\n",
      "Rates:\n",
      "True positive rate: 0.6995073891625616\n",
      "False positive rate: 0.2111111111111111\n",
      "True negative rate: 0.8716216216216216\n",
      "False negative rate: 0.19122257053291536\n",
      "\n",
      "TEST EVALUATION\n",
      "Accuracy: 0.7767441860465116\n",
      "\n",
      "Confusion matrix:\n",
      "          Pred -  Pred +\n",
      "Actual -     101      27\n",
      "Actual +      21      66\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81       128\n",
      "           1       0.71      0.76      0.73        87\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       215\n",
      "   macro avg       0.77      0.77      0.77       215\n",
      "weighted avg       0.78      0.78      0.78       215\n",
      "\n",
      "\n",
      "Rates:\n",
      "True positive rate: 0.7586206896551724\n",
      "False positive rate: 0.2903225806451613\n",
      "True negative rate: 0.7890625\n",
      "False negative rate: 0.1721311475409836\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newton_preds_train, newton_preds_test, newton_model = adalib.logreg_fit_and_predict(lr_titanic.train[lr_titanic.xcols], lr_titanic.train.survived, lr_titanic.test[lr_titanic.xcols], lr_titanic.test.survived, solver=\"newton-cg\")\n",
    "print(\"TRAIN EVALUATION\")\n",
    "adalib.logreg_evaluate_model(lr_titanic.train.survived, newton_preds_train)\n",
    "\n",
    "print(\"TEST EVALUATION\")\n",
    "adalib.logreg_evaluate_model(lr_titanic.test.survived, newton_preds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Which performs better on your in-sample data?\n",
    "\n",
    "newton-cg, but not by much (about ~0.1 more accurate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Save the best model in logit_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_fit = newton_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = DataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.df = get_iris_data()\n",
    "iris.df = prep_iris(iris.df)\n",
    "iris.train, iris.test = train_test_split(iris.df, test_size=0.3, random_state=123, stratify=iris.df[[\"species\"]])\n",
    "iris.xcols = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN EVALUATION\n",
      "Accuracy: 1.0\n",
      "\n",
      "Confusion matrix:\n",
      "                   Pred setosa  Pred versicolor  Pred virginica\n",
      "Actual setosa               35                0               0\n",
      "Actual versicolor            0               35               0\n",
      "Actual virginica             0                0              35\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        35\n",
      "  versicolor       1.00      1.00      1.00        35\n",
      "   virginica       1.00      1.00      1.00        35\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       105\n",
      "   macro avg       1.00      1.00      1.00       105\n",
      "weighted avg       1.00      1.00      1.00       105\n",
      "\n",
      "\n",
      "True setosa rate:  1.000\n",
      "False setosa rate:  0.000\n",
      "\n",
      "True versicolor rate:  1.000\n",
      "False versicolor rate:  0.000\n",
      "\n",
      "True virginica rate:  1.000\n",
      "False virginica rate:  0.000\n",
      "\n",
      "TEST EVALUATION\n",
      "Accuracy: 0.8666666666666667\n",
      "\n",
      "Confusion matrix:\n",
      "                   Pred setosa  Pred versicolor  Pred virginica\n",
      "Actual setosa               15                0               0\n",
      "Actual versicolor            0               11               4\n",
      "Actual virginica             0                2              13\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        15\n",
      "  versicolor       0.85      0.73      0.79        15\n",
      "   virginica       0.76      0.87      0.81        15\n",
      "\n",
      "   micro avg       0.87      0.87      0.87        45\n",
      "   macro avg       0.87      0.87      0.87        45\n",
      "weighted avg       0.87      0.87      0.87        45\n",
      "\n",
      "\n",
      "True setosa rate:  1.000\n",
      "False setosa rate:  0.000\n",
      "\n",
      "True versicolor rate:  0.733\n",
      "False versicolor rate:  0.154\n",
      "\n",
      "True virginica rate:  0.867\n",
      "False virginica rate:  0.235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris.pred_train, iris.pred_test, iris.classes, iris.model = adalib.dectree_fit_and_predict(\n",
    "    iris.train[iris.xcols], iris.train.species, iris.test[iris.xcols], iris.test.species\n",
    ")\n",
    "\n",
    "print(\"TRAIN EVALUATION\")\n",
    "adalib.dectree_evaluate_model(iris.train.species, iris.pred_train, iris.classes)\n",
    "\n",
    "print(\"TEST EVALUATION\")\n",
    "adalib.dectree_evaluate_model(iris.test.species, iris.pred_test, iris.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run through steps 2-4 using entropy as your measure of impurity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_entropy = DataSet()\n",
    "iris_entropy.df = iris.df\n",
    "iris_entropy.train = iris.train\n",
    "iris_entropy.test = iris.test\n",
    "iris_entropy.xcols = iris.xcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN EVALUATION\n",
      "Accuracy: 1.0\n",
      "\n",
      "Confusion matrix:\n",
      "                   Pred setosa  Pred versicolor  Pred virginica\n",
      "Actual setosa               35                0               0\n",
      "Actual versicolor            0               35               0\n",
      "Actual virginica             0                0              35\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        35\n",
      "  versicolor       1.00      1.00      1.00        35\n",
      "   virginica       1.00      1.00      1.00        35\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       105\n",
      "   macro avg       1.00      1.00      1.00       105\n",
      "weighted avg       1.00      1.00      1.00       105\n",
      "\n",
      "\n",
      "True setosa rate:  1.000\n",
      "False setosa rate:  0.000\n",
      "\n",
      "True versicolor rate:  1.000\n",
      "False versicolor rate:  0.000\n",
      "\n",
      "True virginica rate:  1.000\n",
      "False virginica rate:  0.000\n",
      "\n",
      "TEST EVALUATION\n",
      "Accuracy: 0.9111111111111111\n",
      "\n",
      "Confusion matrix:\n",
      "                   Pred setosa  Pred versicolor  Pred virginica\n",
      "Actual setosa               15                0               0\n",
      "Actual versicolor            0               11               4\n",
      "Actual virginica             0                0              15\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        15\n",
      "  versicolor       1.00      0.73      0.85        15\n",
      "   virginica       0.79      1.00      0.88        15\n",
      "\n",
      "   micro avg       0.91      0.91      0.91        45\n",
      "   macro avg       0.93      0.91      0.91        45\n",
      "weighted avg       0.93      0.91      0.91        45\n",
      "\n",
      "\n",
      "True setosa rate:  1.000\n",
      "False setosa rate:  0.000\n",
      "\n",
      "True versicolor rate:  0.733\n",
      "False versicolor rate:  0.000\n",
      "\n",
      "True virginica rate:  1.000\n",
      "False virginica rate:  0.211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris_entropy.pred_train, iris_entropy.pred_test, iris_entropy.classes, iris_entropy.model = adalib.dectree_fit_and_predict(\n",
    "    iris_entropy.train[iris_entropy.xcols], iris_entropy.train.species, iris_entropy.test[iris_entropy.xcols], iris_entropy.test.species, criterion=\"entropy\"\n",
    ")\n",
    "\n",
    "print(\"TRAIN EVALUATION\")\n",
    "adalib.dectree_evaluate_model(iris_entropy.train.species, iris_entropy.pred_train, iris_entropy.classes)\n",
    "\n",
    "print(\"TEST EVALUATION\")\n",
    "adalib.dectree_evaluate_model(iris_entropy.test.species, iris_entropy.pred_test, iris_entropy.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Which performs better on your in-sample data?\n",
    "\n",
    "They both perform equally well on the training data. 100% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to run this on the titanic data and then if i have time, create a function to do the decision tree and analysis, then run the test data through the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Save the best model in tree_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_fit = iris_entropy.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_titanic = DataSet()\n",
    "dt_titanic.df = get_titanic_data()\n",
    "dt_titanic.df = prep_titanic(dt_titanic.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "dt_titanic.train, dt_titanic.test = split_titanic(dt_titanic.df)\n",
    "dt_titanic.train, dt_titanic.test = min_max_scale_titanic(dt_titanic.train, dt_titanic.test)\n",
    "dt_titanic.xcols = [\"pclass\", \"age\", \"sibsp\", \"parch\", \"fare\", \"alone\", \"embarked_encode\", \"sex_encode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN EVALUATION\n",
      "Accuracy: 0.843687374749499\n",
      "\n",
      "Confusion matrix:\n",
      "          Pred 0  Pred 1\n",
      "Actual 0     261      35\n",
      "Actual 1      43     160\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87       296\n",
      "           1       0.82      0.79      0.80       203\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       499\n",
      "   macro avg       0.84      0.83      0.84       499\n",
      "weighted avg       0.84      0.84      0.84       499\n",
      "\n",
      "\n",
      "True 0 rate:  0.882\n",
      "False 0 rate:  0.141\n",
      "\n",
      "True 1 rate:  0.788\n",
      "False 1 rate:  0.179\n",
      "\n",
      "TEST EVALUATION\n",
      "Accuracy: 0.813953488372093\n",
      "\n",
      "Confusion matrix:\n",
      "          Pred 0  Pred 1\n",
      "Actual 0     105      23\n",
      "Actual 1      17      70\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84       128\n",
      "           1       0.75      0.80      0.78        87\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       215\n",
      "   macro avg       0.81      0.81      0.81       215\n",
      "weighted avg       0.82      0.81      0.81       215\n",
      "\n",
      "\n",
      "True 0 rate:  0.820\n",
      "False 0 rate:  0.139\n",
      "\n",
      "True 1 rate:  0.805\n",
      "False 1 rate:  0.247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_titanic.pred_train, dt_titanic.pred_test, dt_titanic.classes, dt_titanic.model = adalib.dectree_fit_and_predict(\n",
    "    dt_titanic.train[dt_titanic.xcols], dt_titanic.train.survived, dt_titanic.test[dt_titanic.xcols], dt_titanic.test.survived, max_depth=4\n",
    ")\n",
    "\n",
    "print(\"TRAIN EVALUATION\")\n",
    "adalib.dectree_evaluate_model(dt_titanic.train.survived, dt_titanic.pred_train, dt_titanic.classes)\n",
    "\n",
    "print(\"TEST EVALUATION\")\n",
    "adalib.dectree_evaluate_model(dt_titanic.test.survived, dt_titanic.pred_test, dt_titanic.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_titanic_entropy = DataSet()\n",
    "dt_titanic_entropy.df = get_titanic_data()\n",
    "dt_titanic_entropy.df = prep_titanic(dt_titanic_entropy.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "dt_titanic_entropy.train, dt_titanic_entropy.test = split_titanic(dt_titanic_entropy.df)\n",
    "dt_titanic_entropy.train, dt_titanic_entropy.test = min_max_scale_titanic(dt_titanic_entropy.train, dt_titanic_entropy.test)\n",
    "dt_titanic_entropy.xcols = [\"pclass\", \"age\", \"sibsp\", \"parch\", \"fare\", \"alone\", \"embarked_encode\", \"sex_encode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN EVALUATION\n",
      "Accuracy: 0.8557114228456913\n",
      "\n",
      "Confusion matrix:\n",
      "          Pred 0  Pred 1\n",
      "Actual 0     289       7\n",
      "Actual 1      65     138\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89       296\n",
      "           1       0.95      0.68      0.79       203\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       499\n",
      "   macro avg       0.88      0.83      0.84       499\n",
      "weighted avg       0.87      0.86      0.85       499\n",
      "\n",
      "\n",
      "True 0 rate:  0.976\n",
      "False 0 rate:  0.184\n",
      "\n",
      "True 1 rate:  0.680\n",
      "False 1 rate:  0.048\n",
      "\n",
      "TEST EVALUATION\n",
      "Accuracy: 0.8\n",
      "\n",
      "Confusion matrix:\n",
      "          Pred 0  Pred 1\n",
      "Actual 0     123       5\n",
      "Actual 1      38      49\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.96      0.85       128\n",
      "           1       0.91      0.56      0.70        87\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       215\n",
      "   macro avg       0.84      0.76      0.77       215\n",
      "weighted avg       0.82      0.80      0.79       215\n",
      "\n",
      "\n",
      "True 0 rate:  0.961\n",
      "False 0 rate:  0.236\n",
      "\n",
      "True 1 rate:  0.563\n",
      "False 1 rate:  0.093\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_titanic_entropy.pred_train, dt_titanic_entropy.pred_test, dt_titanic_entropy.classes, dt_titanic_entropy.model = adalib.dectree_fit_and_predict(\n",
    "    dt_titanic_entropy.train[dt_titanic_entropy.xcols], dt_titanic_entropy.train.survived, dt_titanic_entropy.test[dt_titanic_entropy.xcols], dt_titanic_entropy.test.survived, criterion=\"entropy\",\n",
    "    max_depth=5\n",
    ")\n",
    "\n",
    "print(\"TRAIN EVALUATION\")\n",
    "adalib.dectree_evaluate_model(dt_titanic_entropy.train.survived, dt_titanic_entropy.pred_train, dt_titanic_entropy.classes)\n",
    "\n",
    "print(\"TEST EVALUATION\")\n",
    "adalib.dectree_evaluate_model(dt_titanic_entropy.test.survived, dt_titanic_entropy.pred_test, dt_titanic_entropy.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
